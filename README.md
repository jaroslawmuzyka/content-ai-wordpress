SEO 3.0 Content Factory 
==========================

**SEO 3.0 Content Factory**to zaawansowany panel sterowania (Controller) zbudowany w**Streamlit**, su偶cy do masowego, sekwencyjnego generowania zoptymalizowanych artyku贸w SEO.

Narzdzie zarzdza procesem od sowa kluczowego do gotowego artykuu HTML, wykorzystujc baz danych**Supabase**do zarzdzania stanem kolejki oraz silnik**Dify (LLM Workflow)**do realizacji zada AI.

 G贸wne Funkcjonalnoci
-------------------------

-   **Masowe Przetwarzanie (Batch Processing):**Obsuga setek temat贸w jednoczenie z inteligentn kolejk.

    -   **Trwao Danych (State Persistence):**Wszystkie dane s zapisywane w**Supabase**. Zamknicie przegldarki nie powoduje utraty postp贸w.

    -   **Architektura 5-etapowa:**Pena kontrola nad ka偶dym etapem powstawania treci (Research -> Nag贸wki -> RAG -> Brief -> Pisanie).

    -   **Edycja "Human-in-the-loop":**Mo偶liwo rcznej edycji struktury nag贸wk贸w ("Nag贸wki Finalne") przed wygenerowaniem treci, co zapobiega halucynacjom AI.

    -   **Import/Export:**Obsuga plik贸w.xlsxi.csvz inteligentnym mapowaniem kolumn.

* * * * *

 Architektura Systemu
-----------------------

System skada si z trzech g贸wnych komponent贸w:

-   **Frontend (Streamlit):**Interfejs u偶ytkownika, kt贸ry wywietla tabel zada, pozwala na selekcj wierszy i uruchamianie proces贸w. Dziaa w przegldarce.

    -   **Backend / State (Supabase):**Baza danych PostgreSQL przechowujca wszystkie dane (sowa kluczowe, wyniki researchu, statusy, wygenerowane treci).

    -   **AI Logic (Dify):**Zewntrzny silnik workflow, kt贸ry wykonuje "ci偶k prac" (zapytania do LLM, scraping, analiza SERP).

### Przepyw danych (Workflow)

Aplikacja realizuje proces w 5 odseparowanych krokach:

-   ** Research:**Analiza sowa kluczowego, pobranie fraz z SERP (SerpData) oraz Senuto, budowa grafu informacji.

    -   ** Nag贸wki:**Generowanie struktury artykuu (H2, pytania). System proponuje nag贸wki, kt贸re trafiaj do kolumny roboczej, a nastpnie s kopiowane do kolumny**Nag贸wki (Finalne)**(kt贸r u偶ytkownik mo偶e edytowa).

    -   ** RAG (Retrieval-Augmented Generation):**Budowa bazy wiedzy na podstawie nag贸wk贸w konkurencji (scraping treci konkurencji).

    -   ** Brief:**Mapowanie s贸w kluczowych i wiedzy do konkretnych nag贸wk贸w. Generuje format JSON (dla AI) oraz HTML (dla czowieka).

    -   **锔 Generowanie Contentu:**Iteracyjne (ptla po nag贸wkach) pisanie artykuu sekcja po sekcji na podstawie kolumnyNag贸wki (Finalne), wykorzystujc zgromadzon wiedz (RAG) i instrukcje.

* * * * *

 Wymagania i Instalacja
-------------------------

### 1\. Wymagania systemowe

-   Python 3.8+

    -   Dostp do instancji Dify z odpowiednimi Workflow

    -   Konto Supabase (Baza danych)

### 2\. Instalacja zale偶noci

codeBash

```
pip install -r requirements.txt
```

Plikrequirements.txtpowinien zawiera:

codeText

```
streamlit
pandas
requests
supabase
openpyxl
```

### 3\. Konfiguracja Secrets

Utw贸rz plik.streamlit/secrets.tomlw g贸wnym katalogu projektu i uzupenij go kluczami API:

codeToml

```
[general]
APP_PASSWORD = "TwojeHasloDoAplikacji"

[SUPABASE]
URL = "https://twoja-instancja.supabase.co"
KEY = "twoj-klucz-publiczny-supabase"

[dify]
BASE_URL = "http://twoja-instancja-dify/v1"
API_USER = "nazwa-uzytkownika"
# Klucze API do poszczeg贸lnych Workflow w Dify
API_KEY_RESEARCH = "app-..."
API_KEY_HEADERS = "app-..."
API_KEY_RAG = "app-..."
API_KEY_BRIEF = "app-..."
API_KEY_WRITE = "app-..."
API_KEY_AUDIT = "app-..."
```

### 4\. Schemat Bazy Danych (Supabase)

W panelu SQL Editor w Supabase uruchom poni偶szy kod, aby utworzy wymagan tabel:

codeSQL

```
CREATE TABLE IF NOT EXISTS seo_content_tasks (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    keyword TEXT NOT NULL,
    language TEXT DEFAULT 'pl',
    aio_prompt TEXT,

    -- Etap 1
    status_research TEXT DEFAULT 'Oczekuje',
    serp_phrases TEXT,
    senuto_phrases TEXT,
    info_graph TEXT,
    competitors_headers TEXT,
    knowledge_graph TEXT,

    -- Etap 2
    status_headers TEXT DEFAULT 'Oczekuje',
    headers_expanded TEXT,
    headers_h2 TEXT,
    headers_questions TEXT,
    headers_final TEXT, -- Kluczowa kolumna edycyjna

    -- Etap 3
    status_rag TEXT DEFAULT 'Oczekuje',
    rag_content TEXT,
    rag_general TEXT,

    -- Etap 4
    status_brief TEXT DEFAULT 'Oczekuje',
    brief_json TEXT,
    brief_html TEXT,

    -- Dodatki
    instructions TEXT,

    -- Etap 5
    status_writing TEXT DEFAULT 'Oczekuje',
    final_article TEXT
);
```

* * * * *

 Instrukcja U偶ytkowania
-------------------------

-   **Uruchomienie:**

    codeBash

    ```
    streamlit run app.py
    ```

    -   **Logowanie:**Wpisz haso zdefiniowane wsecrets.toml.

    -   **Import:**Wgraj plik Excel/CSV ze sowami kluczowymi lub dodaj temat rcznie.

    -   **Proces:**

    -   Zaznacz wiersze (checkboxSelect).

        -   Klikaj kolejne przyciski proces贸w (Research -> Nag贸wki -> ...).

        -   **Wa偶ne:**Przed klikniciem "Generuj Content", sprawd藕 kolumn**Nag贸wki (Finalne)**. To z niej system bierze struktur artykuu. Mo偶esz j rcznie edytowa w tabeli.

    -   **Export:**Gotowe artykuy (kod HTML) s widoczne w podgldzie i zapisane w bazie Supabase. Mo偶esz je skopiowa lub wyeksportowa.

* * * * *

З Zale偶noci i API
-------------------

Skrypt czy si z nastpujcymi punktami kocowymi Dify API:

-   workflows/run- Tryb blokujcy (blocking), co oznacza, 偶e Streamlit czeka na zakoczenie generowania przez AI przed aktualizacj bazy.

* * * * *

 Bezpieczestwo
-----------------

-   **Haso aplikacji:**Proste zabezpieczenie przed nieautoryzowanym dostpem do UI.

    -   **Supabase RLS:**Mo偶liwo wczenia Row Level Security w bazie danych dla dodatkowej ochrony.

    -   **Secrets:**Klucze API nie s przechowywane w kodzie, lecz w pliku konfiguracyjnym niepodlegajcym wersjonowaniu (git ignore).
